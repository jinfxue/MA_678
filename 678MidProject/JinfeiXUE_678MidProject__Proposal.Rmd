---
title: "Midterm Project Proposal"
author: "Jinfei Xue"
date: "12 November, 2018"
output:
  html_document:
    df_print: paged
  word_document: default
subtitle: Black Friday Analysis
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
#install.packages("splitstackshape")
library(dplyr)
library(sampling)
library(splitstackshape)
library(ggplot2)
library(lme4)
library(car) #vif
library(MASS)

```


# 1 Introduction

A retail company “ABC Private Limited” wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summary of various customers for selected high volume products from last month. The data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and Total purchase_amount of each client from last month.

Now, they want to build a model to predict the purchase amount of customer against the other variables which will help them to create personalized offer for customers. Here I have to mention that because of the privacy, the occupation, City_Category, product categories are masked and the categories are represented by numbers or letters.


# 2 Data

Both train and test data can be downloaded from the website https://datahack.analyticsvidhya.com/contest/black-friday/?utm_source=auto-email. The train dataset has 550,068 observations and 12 variables while the test data, which contains similar data as train except for their purchase amount, has 233,599 observations.

In the two datasets, the main variables are listed as follows:

- User_ID (as group)

- Gender (M/F)

- Age (Age in bins)

- Occupation (0, 1, ..., 20)

- City_Category (A/B/C)

- Stay_In_Current_City_Years (the number of years stay in current city)

- Marital_Status (0/1)

- Product_Category_1 (the number of bought products in category 1)

- Product_Category_2 (the number of bought products in category 2)

- Product_Category_3 (the number of bought products in category 3)

- Purchase (Purchase amount in dollars)

## 2.1 Data Structure

```{r, message = FALSE, echo = FALSE} 
#input data
data <- read.csv("train.csv")

#print head data
head(data)

#data structure
glimpse(data)
summary(data)
```

## 2.2 Random Sampling

```{r, warning=FALSE, message=FALSE}
# Sample groups from original data
set.seed(123)
index <- data_frame(User_ID = sample(unique(data$User_ID), 200, replace = FALSE)) %>%
  arrange(User_ID)
sample <- inner_join(data, index) %>%
  arrange(User_ID)
```

## 2.3 Clean the Sample Data

```{r, warning=FALSE, message=FALSE}
sapply(sample, function(x) sum(is.na(x)))
# Because NAs only happen in product category variables and it represents the client didn't buy any products in the category, I replace NA with zero.
sample[is.na(sample)] <- 0
sum(is.na(sample)) #check

# transfer occupation to factor
sample$Occupation <- as.factor(sample$Occupation)

# replace outliers with median value of purchase amount
boxplot(sample$Purchase, main="Purchase Amount", boxwex=0.1)
outlier_values <- boxplot.stats(sample$Purchase)$out  # outlier values
sample$Purchase[which(sample$Purchase %in% outlier_values)]=median(sample$Purchase)
```

## 2.4 Train and Test Datasets

```{r, warning=FALSE, message=FALSE}
# Check the minimum number of obeservations in groups
group <- sample %>%
  group_by(User_ID) %>% 
  summarise(number = n()) %>%
  arrange(User_ID) 
min(group$number)
# So we can divide the sample into train and test datasets by groups

# Train dataset
set.seed(221)
bf <- stratified(sample, "User_ID", .7)

# Test dataset
bf_test <- anti_join(sample, bf)

# Test whether User_ID in test dataset is a subset of User_ID in train dataset
sum(unique(bf_test$User_ID) %in% unique(bf$User_ID))==length(unique(bf_test$User_ID))
```


# 3 Exploratory Data Analysis

## 3.1 Total purchase distribution

```{r}
#total purchaser
bf %>%
  select(User_ID) %>%
  unique() %>%
  nrow() %>%
  paste("buyers sampled registered at Black Friday")
```

```{r}
bf1 <- bf %>% 
  group_by(User_ID, Gender, Age, Occupation, City_Category, 
           Stay_In_Current_City_Years, Marital_Status) %>%
  summarise(total_Product_Category_1 = sum(Product_Category_1), 
            total_Product_Category_2 = sum(Product_Category_2),
            total_Product_Category_3 = sum(Product_Category_3),
            total_purchase = sum(Purchase)) 
summary(bf1$total_purchase)

ggplot(data = bf1, aes(x = total_purchase)) + 
  geom_histogram(col = 'black', fill = 'blue', binwidth = 300000, center = 150000) +
  labs(x = 'Dollars', y = 'the Number of Buyers', 
       title = "Figure3.1 Distribution of total purchasing by buyers") + 
  scale_y_continuous(limits = c(0,2000), breaks = c(0,500,1000,1500,2000)) + 
  scale_x_continuous(labels = scales::comma) #prevent scientific number in x-axis
```

## 3.2 Total number in each product category by gender

```{r}
bf2 <- bf %>%
  group_by(Gender) %>%
  summarise(Product_Category_1 = sum(Product_Category_1), 
            Product_Category_2 = sum(Product_Category_2), 
            Product_Category_3 = sum(Product_Category_3)) %>% 
  gather(key = Product_Category, value = total_number,
         Product_Category_1,Product_Category_2,Product_Category_3)

ggplot(data = bf2, aes(x=Product_Category, y = total_number,fill = Gender)) +
  geom_col() +
  labs(x = 'Product Category', y = 'Total Number (units)', 
       title = "Figure3.2 Total number in each product category by gender") + 
  guides(fill=guide_legend(title = "Gender")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis
```

We can see the product category 2 is most popular in the retail store.

## 3.3 Total purchasing in each city by gender

```{r}
bf3 <- bf %>%
  group_by(City_Category, Gender) %>%
  summarise(total_purchase = sum(Purchase))

ggplot(data = bf3, aes(x=City_Category, y = total_purchase, fill = Gender)) +
  geom_col() +
  labs(x = 'City Category', y = 'Total Purchase (dollars)', 
       title = "Figure3.3 Total purchasing in each city by gender") + 
  guides(fill=guide_legend(title = "Gender")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis
```


## 3.4 Purchasing in each age range by marital status
From the above data visualization,we find that men are morely to buy,so there comes our next question:men of what age will spend more money.Let's find out.
```{r, message=FALSE, warning=FALSE}
library(tidyr)
bf_age <- bf %>% 
  separate(Age,c("aa","bb")) %>% 
  mutate(aa=as.numeric(aa),bb=as.numeric(bb)) %>% 
  mutate(Age=(aa+bb)/2) %>% 
  dplyr::select(-c(aa,bb))

bf4_1 <- bf_age %>% 
  mutate(age_range=case_when(Age <= 18 ~"Young",Age > 18 & Age <= 35 ~ "Mature",
                             Age > 35 & Age < 55 ~ "Middle-aged"))
bf4_1$age_range<-ifelse(is.na(bf4_1$age_range),"Old",bf4_1$age_range)
bf4_1$age_range<-factor(bf4_1$age_range, levels = c("Young", "Mature", "Middle-aged", "Old"))

attach(bf4_1)
bf4_1$Marital_Status[Marital_Status == 0] <- "Unmarried"
bf4_1$Marital_Status[Marital_Status == 1] <- "Married"

bf4_2 <- bf4_1 %>%
  group_by(age_range, Marital_Status) %>%
  summarise(total_purchase = sum(Purchase))
```

```{r}
ggplot(data = bf4_2, aes(x=age_range, y = total_purchase, fill = Marital_Status)) +
  geom_col() +
  labs(x = 'Age Range', y = 'Total Purchase (dollars)', 
       title = "Figure3.4 Total purchasing in each age range by marital status") + 
  guides(fill=guide_legend(title = "Marital Status")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis

```


```{r}
p1<-bf4_1 %>% 
  filter(Gender=="M") %>% 
  group_by(age_range,Marital_Status) %>% 
  summarise(purchase=median(Purchase)) %>%
  ggplot(aes(x=age_range,y=Marital_Status,fill=purchase))+
  geom_tile()+
  scale_fill_continuous(low="blue",high="red")+
  labs(x = 'Age Range', y = 'Marital Status', 
       title = "Figure3.4.1 Medium purchasing of male in each age range by marital status")
  
p2<-bf4_1 %>% 
  filter(Gender=="F") %>% 
  group_by(age_range,Marital_Status) %>% 
  summarise(purchase=median(Purchase)) %>%
  ggplot(aes(x=age_range,y=Marital_Status,fill=purchase))+
  geom_tile()+
  scale_fill_continuous(low="blue",high="red")+
  labs(x = 'Age Range', y = 'Marital Status', 
       title = "Figure3.4.2 Medium purchasing of female in each age range by marital status")

gridExtra::grid.arrange(p1,p2)
```

## 3.5 Purchasing in each age range by city category

```{r}
bf5 <- bf4_1 %>%
  group_by(age_range, City_Category) %>%
  summarise(total_purchase = sum(Purchase))

  
ggplot(data = bf5, aes(x=age_range, y = total_purchase, fill = City_Category)) +
  geom_col() +
  labs(x = 'Age', y = 'Total Purchase (dollars)', 
       title = "Figure3.5 Total purchasing in each age range by city category") + 
  guides(fill=guide_legend(title = "City Category")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis
```

```{r}
p3<-bf4_1 %>% 
  filter(Gender=="M") %>% 
  group_by(age_range,City_Category) %>% 
  summarise(purchase=median(Purchase)) %>%
  ggplot(aes(x=age_range,y=City_Category,fill=purchase))+
  geom_tile()+
  scale_fill_continuous(low="blue",high="red")+
  labs(x = 'Age Range', y = 'City Category', 
       title = "Figure3.5.1 Medium purchasing of male in each age range by city category")

p4<-bf4_1 %>% 
  filter(Gender=="F") %>% 
  group_by(age_range,City_Category) %>% 
  summarise(purchase=median(Purchase)) %>%
  ggplot(aes(x=age_range,y=City_Category,fill=purchase))+
  geom_tile()+
  scale_fill_continuous(low="blue",high="red")+
  labs(x = 'Age Range', y = 'City Category', 
       title = "Figure3.5.2 Medium purchasing of female in each age range by city category")

gridExtra::grid.arrange(p3,p4)
```

## 3.6 Toal purchasing in each occupation by city category

```{r}
bf6 <- bf %>%
  group_by(City_Category, Occupation) %>%
  summarise(total_purchase = sum(Purchase))

ggplot(data = bf6, aes(x=Occupation, y = total_purchase, fill = City_Category)) +
  geom_col() +
  labs(x = 'Occupation', y = 'Total Purchase (dollars)', 
       title = "Figure3.6 Toal purchasing in each occupation by city category") + 
  guides(fill=guide_legend(title = "City Category")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis
```

## 3.7 Toal purchasing in each occupation by city category

```{r}
bf7 <- bf %>%
  group_by(City_Category, Stay_In_Current_City_Years) %>%
  summarise(total_purchase = sum(Purchase))

ggplot(data = bf7, aes(x=Stay_In_Current_City_Years, y = total_purchase, fill = City_Category)) +
  geom_col() +
  labs(x = 'Years of Staying in Current City (years)', y = 'Total Purchase (dollars)', 
       title = "Figure3.7 Toal purchasing in each category of years of staying in current city by city category") + 
  guides(fill=guide_legend(title = "City Category")) + 
  scale_y_continuous(labels = scales::comma) #prevent scientific number in x-axis
```

## 3.8 Correlation among the number of product_category_1/2/3

```{r, message=FALSE}
library(dplyr)
product <- bf %>%
  select(Product_Category_1, Product_Category_2, Product_Category_3)
res <- cor(product)
round(res, 2)
library(corrplot)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45, title = "Figure3.8 Correlation among the number of product_category_1/2/3")
```




# 4 Modeling and Checking


The predictors include "Gender", "Age", "Occupation", "City_Category", "Stay_In_Current_City_Years", "Marital_Status", "Product_Category_1", "Product_Category_2" and "Product_Category_3". The response variable is "Purchase".

## 4.1 Linear regression model

```{r, message=FALSE, warning=FALSE}
# Standardize the response variable
bf$sd_purchase <- (bf$Purchase-mean(bf$Purchase))/sd(bf$Purchase)
# Fit the full model 
r1 <- lm(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
           Product_Category_2 + Product_Category_3, data = bf)

summary(r1)

# Residual Plot
plot(r1, which = 1)

# Marginal model plots
library(car)
marginalModelPlots(r1)
```

From the residual plot, we can see that the points are not randomly dispersed around the horizontal line at zero(the dashed black line). Also, we can see from the first marginal plot, there exists a big discrepency between the linear regression line and actual data line. And from the third marginal plot, we can conclude the model does not fit the data well.


## 4.2 Polynomial regression model

```{r}
ggplot(bf)+geom_point()+aes(x=Product_Category_1,y=sd_purchase)+
  labs(title = "Figure 4.1.2", 
       subtitle = "The Number of Product Category 1 V.S Standardized Purchase Amount",
       x = "The Number of Products Customers bought in Category 1 (unit)",
       y = "Standardized Purchase Amount (dollars)")
```

From figure 4.1.2, we can see a nonlinear effect of Product_Category_1 on sd_purchase. Therefore, then I will try to fit a polynomial regression model.

```{r, message=FALSE, warning=FALSE}
r2 <- lm(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + 
           poly(Product_Category_1, 2) + Product_Category_2 + Product_Category_3, data = bf)
summary(r2)
#round(r2$coefficients, digits = 2)
# Residual Plot
plot(r2, which = 1)

# Marginal model plots
library(car)
marginalModelPlots(r2)
```

## 4.3 Linear regression model with interaction

```{r, message=FALSE, warning=FALSE}
r3 <- lm(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status +
           Product_Category_2*Product_Category_3, data = bf)
summary(r3)
#round(r2$coefficients, digits = 2)
# Residual Plot
plot(r3, which = 1)

# Marginal model plots
library(car)
marginalModelPlots(r3)
```

We can see the residual plot is a little better than before but there still exists a decreasing trend.


## 4.4 Cumulative logit model

```{r, message=FALSE, warning=FALSE}
plot(bf$sd_purchase)
#axis(side=2, at=seq(-2, 3, by=0.01))

ggplot(bf)+geom_point()+aes(x=Age,y=sd_purchase)

#histrv <- hist(bf$sd_purchase, breaks = 1000)
#which.min(histrv$density)

```

We can see the standardized purchase amount by age have some gaps although it is a continuous variable. Therefore, I will divide the value of standardized purchase amount into several categories. That is to say, standardized purchase amount is transformed to ordinal variable.

```{r, message=FALSE, warning=FALSE}
# Transform sd_purchase into ordinal variable
# Train dataset
quan <- quantile(bf$sd_purchase)

bf <- bf%>% 
  mutate(purchase_level=case_when(sd_purchase <= quan[2] ~"Low",
                                  sd_purchase > quan[2] & sd_purchase <= quan[3] ~ "Somewhat Low",
                                  sd_purchase > quan[3] & sd_purchase < quan[4] ~ "Somewhat High",
                                  sd_purchase >= quan[4] ~"High"))

bf$purchase_level <- factor(bf$purchase_level, 
                            levels=c("Low", "Somewhat Low", "Somewhat High", "High"), ordered=TRUE)
# Test dataset
bf_test$sd_purchase <- (bf_test$Purchase-mean(bf_test$Purchase))/sd(bf_test$Purchase)
bf_test <- bf_test %>% 
  mutate(purchase_level=case_when(sd_purchase <= quan[2] ~"Low",
                                  sd_purchase > quan[2] & sd_purchase <= quan[3] ~ "Somewhat Low",
                                  sd_purchase > quan[3] & sd_purchase < quan[4] ~ "Somewhat High",
                                  sd_purchase >= quan[4] ~"High"))

bf_test$purchase_level <- factor(bf_test$purchase_level, 
                            levels=c("Low", "Somewhat Low", "Somewhat High", "High"), ordered=TRUE)

```

The new response variable called purchase_level has 4 categories including "Low", "Somewhat Low", "Somewhat High" and "High".

```{r, message=FALSE, warning=FALSE}
# Fit the full model
r4 <- polr(purchase_level ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
           Product_Category_2*Product_Category_3, data = bf)
summary(r4)

ctable <- coef(summary(r4))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable <- cbind(ctable, "p value" = p)
kableExtra::kable(ctable)

# Check the model: Likelihood ratio test
Anova(r4, type = 3)
```




```{r}
# Prediction in test dataset
predict.purchase <- predict(r4, bf_test)  # predict the classes directly
head(predict.purchase)


predicted.prop <- predict(r4, bf_test, type="p")  # predict the probabilites
head(predicted.prop)

# Build a confusion matrix
table(predict.purchase, bf_test$purchase_level)

# Compute the misclassification error rate of prediction
mean(as.character(predict.purchase) != as.character(bf_test$purchase_level))
```

A misclassification error of 60.47% is probably too high. Maybe it can be improved by trying Multilevel model to improve the accuracy.


## 4.5 Mixed Effects Model

With this black friday retail dataset, since each User_ID has multiple purchase records, we can immediately see that this would violate the independence assumption that’s important in linear modeling, which is to say multiple purchase records from the same User_ID cannot be regarded as independent from each other. Besides, in our scenario, every User_ID has a slightly different consumption habit, and this is going to be an idiosyncratic factor that affects the measurements from the different User_IDs.

```{r, message=FALSE, warning=FALSE}
library(radiant.data)

bf_no_pooling <- lmList(sd_purchase ~ Product_Category_2 | User_ID, bf) %>% 
  coef() %>% 
  # Subject IDs are stored as row-names. Make them an explicit column
  rownames_to_column("User_ID") %>% 
  rename(Intercept = `(Intercept)`, Slope = Product_Category_2) %>% 
  add_column(Model = "No pooling") 



bf_pooled <- data_frame(
  Model = "Complete pooling",
  Subject = unique(bf$User_ID[1:6]),
  Intercept = coef(r3)[1], 
  Slope = coef(r3)[2])


```



```{r}
ggplot(bf[1:313,]) + 
  aes(x = Product_Category_2, y = sd_purchase) + 
  stat_smooth(method = "lm", se = FALSE) +
  geom_point() +
  facet_wrap("User_ID") +
  labs(title = "Figure 4.5.1", 
       subtitle = "Product_Category_2 V.S Standardized Purchase Amount by User_ID",
       x = "Product_Category_2", y = "Standardized Purchase Amount") 

```

From the figure 4.5.1, we can see there are differnt trends between groups. Therefore, in order to consider the differences among both individuals (each purchase) and groups (each User_ID), we should then fit the multilevel model.

Individual level variables include "Product_Category_1", "Product_Category_2" and "Product_Category_3". Group level variables include "Gender", "Age", "Occupation", "City_Category", "Stay_In_Current_City_Years" and "Marital_Status".

### 4.5.1 Mixed Effects Model (vary by intercept)

First, we fit a mixed effects model with varying intercepts by groups (User_ID).

```{r, message=FALSE, warning=FALSE}
r5_0 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
             Product_Category_2 + Product_Category_3 + (1|User_ID), data = bf)
r5_1 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
             Product_Category_2 + (1|User_ID), data = bf)
r5_2 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
             Product_Category_3 + (1|User_ID), data = bf)
r5_3 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status +
             Product_Category_2 + Product_Category_3 + (1|User_ID), data = bf)
anova(r5_0, r5_1, r5_2, r5_3) 
anova(r5_2, r5_0)


r5 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
             Product_Category_2*Product_Category_3 + (1|User_ID), data = bf)
anova(r5, r5_0)
```

From the results of anova method to compare models, we can see if we remove one continuous variable from r5_0 model, we should choose to remove Product_Category_2 (in r5_2). However, when we campare r5_0 and r5_2 model, anova test shows we cannot reject the null hypothesis, which means the two models are equal in fitting the data. Then, I try to add the interaction between Product_Category_2 and Product_Category_3 in model r5, the anova test for r5 and r5_0 shows r5 model fits the data better. Therefore, in the mixed effects model with varying intercepts, r5 model fits the data well.

```{r, message=FALSE, warning=FALSE}
summary(r5)
```

### 4.1.6 Multilevel regression (varying slopes)

```{r}
ggplot(bf)+geom_point()+aes(x=Product_Category_1,y=sd_purchase)+
  facet_wrap(~User_ID)+geom_smooth(method="lm",se=FALSE)+
  xlab("age in days")+ ylab("distance in pixels")
```



```{r}
r6 <- lmer(sd_purchase ~ Gender + Age + Occupation + City_Category + 
           Stay_In_Current_City_Years + Marital_Status + Product_Category_1 +
             Product_Category_2 + Product_Category_3 + (1+|User_ID), data = bf)
summary(r6)
```


```{r}
#createDataPartition
```

### 4.2.4 Multilevel generalized linear models

From figure(distribution), we can see the black friday purchase data has the 

```{r}

#summary(bf$Purchase)
#summary(bf1$log.total)

ggplot(data = bf1, aes(x = log.total)) + 
  geom_histogram(col = 'black', fill = 'blue', binwidth = 0.05, center = 12) +
  labs(x = 'Dollars', y = 'the Number of Buyers', 
       title = "Figure3.1 Distribution of total purchasing by buyers")


ggplot(data = bf1, aes(x = total_purchase)) + 
  geom_histogram(col = 'black', fill = 'blue', binwidth = 300000, center = 150000) +
  labs(x = 'Dollars', y = 'the Number of Buyers', 
       title = "Figure3.1 Distribution of total purchasing by buyers") + 
  scale_y_continuous(limits = c(0,2000), breaks = c(0,500,1000,1500,2000)) + 
  scale_x_continuous(labels = scales::comma) #prevent scientific number in x-axis





```





## 4.3 Model Checking

```{r}

```

## 4.3 Prediction








## 5.3 


# 3 Objectives

* Clean Data
* Exploratory Data Analysis: *creating graphics*.
* Modeling and Prediction: *using multilevel model, model checking and prediction*.
* Assessment and Discussions: *assessing the limitations of the result and discussing future research directions*.
